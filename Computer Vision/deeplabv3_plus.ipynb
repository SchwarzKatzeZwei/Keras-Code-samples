{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "deeplabv3_plus",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('tf': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "interpreter": {
      "hash": "5f345f7e068d398d16713d0d450186d3eb8638a9481e17a61f22c1d58da32f95"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass semantic segmentation using DeepLabV3+(DeepLabV3+によるマルチクラスセマンティックセグメンテーション)\n",
        "\n",
        "**Author:** [Soumik Rakshit](http://github.com/soumik12345)<br>\n",
        "**Date created:** 2021/08/31<br>\n",
        "**Last modified:** 2021/09/1<br>\n",
        "**Description:** Implement DeepLabV3+ architecture for Multi-class Semantic Segmentation."
      ],
      "metadata": {
        "id": "g-ShFlrAmC2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 序章\n",
        "\n",
        "画像の各ピクセルに意味的なラベルを付与することを目的としたセマンティックセグメンテーションは、コンピュータビジョンの重要なタスクです。\n",
        "この例ではマルチクラスセマンティックセグメンテーションのための **DeepLabV3+** モデルを実装しました。\n",
        "このモデルは、セマンティックセグメンテーションのベンチマークで優れた性能を発揮する完全畳み込み型のアーキテクチャです。\n",
        "\n",
        "### リファレンス\n",
        "\n",
        "- [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n",
        "- [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)\n",
        "- [DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/abs/1606.00915)"
      ],
      "metadata": {
        "id": "K4Td7qLYmC2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データのダウンロード\n",
        "\n",
        "ここでは、[Crowd Instance-level Human Parsing Dataset](https://arxiv.org/abs/1811.12596)を使用します。\n",
        "を使ってモデルを学習します。Crowd Instance-level Human Parsing (CIHP)データセットには、38,280枚の多様な人間の画像が含まれています。\n",
        "CIHPの各画像には、インスタンスレベルの識別だけでなく、20のカテゴリに対するピクセル単位のアノテーションが付けられています。\n",
        "このデータセットは、「人間のパーツのセグメンテーション」タスクに使用することができます。"
      ],
      "metadata": {
        "id": "oE1wQiwDmC2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "outputs": [],
      "metadata": {
        "id": "W5NU76shmC2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1B9A9UCJYMwTL4oBEo4RZfbMZMaZhKJaz\"\n",
        "!unzip -q instance-level-human-parsing.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1B9A9UCJYMwTL4oBEo4RZfbMZMaZhKJaz\n",
            "To: /Users/shogo/dev/github/Keras-Code-samples/Computer Vision/instance-level-human-parsing.zip\n",
            "2.91GB [01:26, 33.6MB/s]\n"
          ]
        }
      ],
      "metadata": {
        "id": "YXfe_GkGmC2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlowデータセットの作成\n",
        "\n",
        "Training on the entire CIHP dataset with 38,280 images takes a lot of time, hence we will be using\n",
        "a smaller subset of 200 images for training our model in this example.\n",
        "38,280枚の画像を含むCIHPデータセット全体の学習には多くの時間がかかるため、この例では200枚の画像からなる小さなサブセットを使ってモデルを学習します．"
      ],
      "metadata": {
        "id": "CBWDuvdkmC2W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "IMAGE_SIZE = 512\n",
        "BATCH_SIZE = 4\n",
        "NUM_CLASSES = 20\n",
        "DATA_DIR = \"./instance-level_human_parsing/instance-level_human_parsing/Training\"\n",
        "NUM_TRAIN_IMAGES = 1000\n",
        "NUM_VAL_IMAGES = 50\n",
        "\n",
        "train_images = sorted(glob(os.path.join(DATA_DIR, \"Images/*\")))[:NUM_TRAIN_IMAGES]\n",
        "train_masks = sorted(glob(os.path.join(DATA_DIR, \"Category_ids/*\")))[:NUM_TRAIN_IMAGES]\n",
        "val_images = sorted(glob(os.path.join(DATA_DIR, \"Images/*\")))[\n",
        "    NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES\n",
        "]\n",
        "val_masks = sorted(glob(os.path.join(DATA_DIR, \"Category_ids/*\")))[\n",
        "    NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES\n",
        "]\n",
        "\n",
        "\n",
        "def read_image(image_path, mask=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    if mask:\n",
        "        image = tf.image.decode_png(image, channels=1)\n",
        "        image.set_shape([None, None, 1])\n",
        "        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "    else:\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "        image.set_shape([None, None, 3])\n",
        "        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "        image = image / 127.5 - 1\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_data(image_list, mask_list):\n",
        "    image = read_image(image_list)\n",
        "    mask = read_image(mask_list, mask=True)\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def data_generator(image_list, mask_list):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_dataset = data_generator(train_images, train_masks)\n",
        "val_dataset = data_generator(val_images, val_masks)\n",
        "\n",
        "print(\"Train Dataset:\", train_dataset)\n",
        "print(\"Val Dataset:\", val_dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset: <BatchDataset shapes: ((4, 512, 512, 3), (4, 512, 512, 1)), types: (tf.float32, tf.float32)>\n",
            "Val Dataset: <BatchDataset shapes: ((4, 512, 512, 3), (4, 512, 512, 1)), types: (tf.float32, tf.float32)>\n"
          ]
        }
      ],
      "metadata": {
        "id": "ChhH2M05mC2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeepLabV3+モデルの構築\n",
        "\n",
        "DeepLabv3+はDeepLabv3を拡張し、エンコーダ・デコーダ構造を追加しています。\n",
        "エンコーダモジュールはマルチスケールのコンテクスト情報を複数のスケールでの拡張畳み込みで処理する。\n",
        "デコーダモジュールは、オブジェクトの境界に沿ってセグメンテーション結果を改良します。\n",
        "\n",
        "![](https://github.com/lattice-ai/DeepLabV3-Plus/raw/master/assets/deeplabv3_plus_diagram.png)\n",
        "\n",
        "**Dilated convolution:** Dilated convolutionでは、ネットワークの深部に行くほど、ストライドを一定に保ちながら、視野を広くすることができます。\n",
        "パラメータの数や計算量を増やすことなく、ストライドを一定に保ったまま視野を広げることができます。\n",
        "視野を広げることができます。さらに、より大きな特徴マップを出力することができます。\n",
        "セマンティック・セグメンテーションに有効です。\n",
        "\n",
        "**Dilated Spatial Pyramid Pooling**を採用した理由は、サンプリングレートが大きくなると、有効なフィルターウェイト(有効なフィルタリングを行うためのウェイト)の数が減少することがわかったからです。\n",
        "サンプリングレートが大きくなると，有効なフィルターウェイト（パディングされたゼロではなく，有効な特徴領域に適用されるウェイト）の数が少なくなることが示されているからです。\n",
        "有効なフィルターウェイト（パディングされたゼロではなく、有効な特徴領域に適用されるウェイト）の数が少なくなることが示されたからです。"
      ],
      "metadata": {
        "id": "6OHsCOgMmC2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output"
      ],
      "outputs": [],
      "metadata": {
        "id": "AMDB6tI-mC2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "エンコーダーの特徴は、まずファクター4でバイリニアにアップサンプリングされ、次に\n",
        "同じ空間分解能を持つネットワークバックボーンからの対応する低レベルの特徴と連結されます。\n",
        "この例ではImageNetで事前学習したResNet50をバックボーンモデルとして使用し、\n",
        "バックボーンの`conv4_block6_2_relu`ブロックからの低レベル特徴を使用しています。"
      ],
      "metadata": {
        "id": "Z5rC_wv7mC2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 256, 256, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 128, 128, 256 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 128, 128, 256 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 128, 128, 256 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 128, 128, 64) 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 128, 128, 256 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 128, 128, 256 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 64, 64, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 64, 64, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 64, 64, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 64, 64, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 64, 64, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 32, 32, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 32, 32, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 32, 32, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 32, 32, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 32, 32, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 256)    0           conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 1, 1, 256)    65792       average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 1, 1, 256)    1024        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 256)  65536       conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 256)  589824      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 256)  589824      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  589824      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)         (None, 1, 1, 256)    0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 32, 32, 256)  0           tf.nn.relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)       (None, 32, 32, 256)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)       (None, 32, 32, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)       (None, 32, 32, 256)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)       (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 1280) 0           up_sampling2d[0][0]              \n",
            "                                                                 tf.nn.relu_1[0][0]               \n",
            "                                                                 tf.nn.relu_2[0][0]               \n",
            "                                                                 tf.nn.relu_3[0][0]               \n",
            "                                                                 tf.nn.relu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 256)  327680      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 128, 128, 48) 3072        conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 128, 128, 48) 192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 256 0           tf.nn.relu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)       (None, 128, 128, 48) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128, 128, 304 0           up_sampling2d_1[0][0]            \n",
            "                                                                 tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 128, 128, 256 700416      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 128, 128, 256 1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)       (None, 128, 128, 256 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 128, 128, 256 589824      tf.nn.relu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 128, 128, 256 1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_8 (TFOpLambda)       (None, 128, 128, 256 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 256 0           tf.nn.relu_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 512, 512, 20) 5140        up_sampling2d_2[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 11,857,236\n",
            "Trainable params: 11,824,500\n",
            "Non-trainable params: 32,736\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "-LS3w_8BmC2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習\n",
        "\n",
        "We train the model using sparse categorical crossentropy as the loss function, and\n",
        "Adam as the optimizer.\n",
        "\n",
        "損失関数としてスパースなカテゴリー別クロスエントロピーを用いてモデルを学習し、最適化アルゴリズムとしてAdamを使用しています。"
      ],
      "metadata": {
        "id": "iqBa8k7rmC2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=25)\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x175894700> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x175894700> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            " 39/250 [===>..........................] - ETA: 49:28 - loss: 2.1932 - accuracy: 0.4378"
          ]
        }
      ],
      "metadata": {
        "id": "JdkDfG7UmC2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colormap Overlayによる推論\n",
        "\n",
        "モデルから得られた生の予測値は形状 `(N, 512, 512, 20)` のワンショット符号化テンソルを表します。\n",
        "ここで、20個のチャンネルのそれぞれは予測されたラベルに対応するバイナリマスクです。\n",
        "結果を視覚化するために、RGBのセグメンテーション・マスクとしてプロットします。\n",
        "予測された特定のラベルに対応する固有の色で表されます。\n",
        "各ラベルに対応する色はデータセットの一部として提供された `human_colormap.mat` ファイルから簡単に見つけることができます．\n",
        "また、入力画像にRGBセグメンテーションマスクを重ねて表示することもできます。\n",
        "これは、画像の中に存在するさまざまなカテゴリーをより直感的に識別するのに役立ちます。"
      ],
      "metadata": {
        "id": "JPMj5rbpmC2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Loading the Colormap\n",
        "colormap = loadmat(\n",
        "    \"./instance-level_human_parsing/instance-level_human_parsing/human_colormap.mat\"\n",
        ")[\"colormap\"]\n",
        "colormap = colormap * 100\n",
        "colormap = colormap.astype(np.uint8)\n",
        "\n",
        "\n",
        "def infer(model, image_tensor):\n",
        "    predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
        "    predictions = np.squeeze(predictions)\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def decode_segmentation_masks(mask, colormap, n_classes):\n",
        "    r = np.zeros_like(mask).astype(np.uint8)\n",
        "    g = np.zeros_like(mask).astype(np.uint8)\n",
        "    b = np.zeros_like(mask).astype(np.uint8)\n",
        "    for l in range(0, n_classes):\n",
        "        idx = mask == l\n",
        "        r[idx] = colormap[l, 0]\n",
        "        g[idx] = colormap[l, 1]\n",
        "        b[idx] = colormap[l, 2]\n",
        "    rgb = np.stack([r, g, b], axis=2)\n",
        "    return rgb\n",
        "\n",
        "\n",
        "def get_overlay(image, colored_mask):\n",
        "    image = tf.keras.preprocessing.image.array_to_img(image)\n",
        "    image = np.array(image).astype(np.uint8)\n",
        "    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
        "    return overlay\n",
        "\n",
        "\n",
        "def plot_samples_matplotlib(display_list, figsize=(5, 3)):\n",
        "    _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
        "    for i in range(len(display_list)):\n",
        "        if display_list[i].shape[-1] == 3:\n",
        "            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        else:\n",
        "            axes[i].imshow(display_list[i])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_predictions(images_list, colormap, model):\n",
        "    for image_file in images_list:\n",
        "        image_tensor = read_image(image_file)\n",
        "        prediction_mask = infer(image_tensor=image_tensor, model=model)\n",
        "        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 20)\n",
        "        overlay = get_overlay(image_tensor, prediction_colormap)\n",
        "        plot_samples_matplotlib(\n",
        "            [image_tensor, overlay, prediction_colormap], figsize=(18, 14)\n",
        "        )"
      ],
      "outputs": [],
      "metadata": {
        "id": "MNZorRjAmC2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習画像の推論"
      ],
      "metadata": {
        "id": "qtm6CzR0mC2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_predictions(train_images[:4], colormap, model=model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "S13MNpwdmC2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 検証画像の推論"
      ],
      "metadata": {
        "id": "hR32QaccmC2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_predictions(val_images[:4], colormap, model=model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3BNQ2rF5mC2a"
      }
    }
  ]
}