{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "3D_image_classification",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3D image classification from CT scans\n",
        "\n",
        "**Author:** [Hasib Zunair](https://twitter.com/hasibzunair)<br>\n",
        "**Date created:** 2020/09/23<br>\n",
        "**Last modified:** 2020/09/23<br>\n",
        "**Description:** Train a 3D convolutional neural network to predict presence of pneumonia."
      ],
      "metadata": {
        "id": "JQP-CdsJLttM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This example will show the steps needed to build a 3D convolutional neural network (CNN) to predict the presence of viral pneumonia in computer tomography (CT) scans. 2D CNNs are commonly used to process RGB images (3 channels).  \n",
        "A 3D CNN is simply the 3D equivalent: it takes as input a 3D volume or a sequence of 2D frames (e.g. slices in a CT scan), 3D CNNs are a powerful model for learning representations for volumetric data.\n",
        "\n",
        "この例では、コンピュータ断層撮影（CT）スキャンにおけるウイルス性肺炎の有無を予測するための3Dコンボリューショナル・ニューラル・ネットワーク（CNN）を構築するために必要な手順を示します。2D CNNは通常、RGB画像（3チャンネル）の処理に使われます。  \n",
        "3D CNNは単純に3Dに相当するもので、3Dボリュームまたは2Dフレームのシーケンス（例：CTスキャンのスライス）を入力とし、3D CNNはボリュームデータの表現を学習するための強力なモデルである。\n",
        "\n",
        "## References\n",
        "\n",
        "- [A survey on Deep Learning Advances on Different 3D DataRepresentations](https://arxiv.org/pdf/1808.01462.pdf)\n",
        "- [VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition](https://www.ri.cmu.edu/pub_files/2015/9/voxnet_maturana_scherer_iros15.pdf)\n",
        "- [FusionNet: 3D Object Classification Using MultipleData Representations](http://3ddl.cs.princeton.edu/2016/papers/Hegde_Zadeh.pdf)\n",
        "- [Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction](https://arxiv.org/abs/2007.13224)"
      ],
      "metadata": {
        "id": "lOEBdiFMLttN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "YyKiCr6TLttN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "outputs": [],
      "metadata": {
        "id": "vVTItmS_LttN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the MosMedData: Chest CT Scans with COVID-19 Related Findings\n",
        "\n",
        "In this example, we use a subset of the\n",
        "[MosMedData: Chest CT Scans with COVID-19 Related Findings](https://www.medrxiv.org/content/10.1101/2020.05.20.20100362v1).\n",
        "This dataset consists of lung CT scans with COVID-19 related findings, as well as without such findings.\n",
        "\n",
        "この例では、サブセットを使用しています。  \n",
        "[MosMedData: Chest CT Scans with COVID-19 Related Findings](https://www.medrxiv.org/content/10.1101/2020.05.20.20100362v1)です。\n",
        "このデータセットは、COVID-19関連の所見がある肺CTスキャンと、そのような所見がない肺CTスキャンで構成されています。\n",
        "\n",
        "We will be using the associated radiological findings of the CT scans as labels to build a classifier to predict presence of viral pneumonia.  \n",
        "Hence, the task is a binary classification problem.\n",
        "\n",
        "我々は、CTスキャンの関連する放射線学的所見をラベルとして使用し、ウイルス性肺炎の存在を予測する分類器を構築する予定です。  \n",
        "したがって、このタスクは二値の分類問題となります。"
      ],
      "metadata": {
        "id": "lPhkFDk8LttO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Download url of normal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "# Download url of abnormal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "# Make a directory to store the data.\n",
        "os.makedirs(\"MosMedData\")\n",
        "\n",
        "# Unzip data in the newly created directory.\n",
        "with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./MosMedData/\")\n",
        "\n",
        "with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./MosMedData/\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "wpV-EFWWLttO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data and preprocessing\n",
        "\n",
        "The files are provided in Nifti format with the extension .nii. To read the scans, we use the `nibabel` package.  \n",
        "You can install the package via `pip install nibabel`.  \n",
        "CT scans store raw voxel intensity in Hounsfield units (HU).  \n",
        "They range from -1024 to above 2000 in this dataset.  \n",
        "Above 400 are bones with different radiointensity, so this is used as a higher bound. A threshold between -1000 and 400 is commonly used to normalize CT scans.\n",
        "\n",
        "ファイルはNifti形式で提供され、拡張子は.niiです。スキャンデータを読むためには，`nibabel`パッケージを使います。  \n",
        "このパッケージは `pip install nibabel` でインストールできます。  \n",
        "CTスキャンでは、生のボクセル強度をHounsfield units（HU）で保存します。  \n",
        "このデータセットでは、-1024から2000以上の範囲です。  \n",
        "400以上は放射線強度が異なる骨なので、これを上限としています。CTスキャンの正規化には、-1000から400の間の閾値がよく使われます。\n",
        "\n",
        "To process the data, we do the following:\n",
        "\n",
        "* We first rotate the volumes by 90 degrees, so the orientation is fixed\n",
        "* We scale the HU values to be between 0 and 1.\n",
        "* We resize width, height and depth.\n",
        "\n",
        "Here we define several helper functions to process the data.  \n",
        "These functions will be used when building training and validation datasets.  \n",
        "\n",
        "このデータを処理するために、次のようなことを行います。\n",
        "\n",
        "* まず、ボリュームを90度回転させて、向きを固定します。\n",
        "* HUの値を0から1の間になるようにスケーリングします。\n",
        "* 幅、高さ、奥行きのサイズを変更します。\n",
        "\n",
        "ここで、データを処理するためのいくつかのヘルパー関数を定義します。  \n",
        "これらの関数は、トレーニングおよび検証データセットを構築する際に使用されます。"
      ],
      "metadata": {
        "id": "s5C-IXp_LttO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "import nibabel as nib\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "def read_nifti_file(filepath):\n",
        "    \"\"\"Read and load volume\"\"\"\n",
        "    # Read file\n",
        "    scan = nib.load(filepath)\n",
        "    # Get raw data\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "\n",
        "\n",
        "def normalize(volume):\n",
        "    \"\"\"Normalize the volume\"\"\"\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    volume[volume < min] = min\n",
        "    volume[volume > max] = max\n",
        "    volume = (volume - min) / (max - min)\n",
        "    volume = volume.astype(\"float32\")\n",
        "    return volume\n",
        "\n",
        "\n",
        "def resize_volume(img):\n",
        "    \"\"\"Resize across z-axis\"\"\"\n",
        "    # Set the desired depth\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    # Get current depth\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    # Resize across z-axis\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_scan(path):\n",
        "    \"\"\"Read and resize volume\"\"\"\n",
        "    # Read scan\n",
        "    volume = read_nifti_file(path)\n",
        "    # Normalize\n",
        "    volume = normalize(volume)\n",
        "    # Resize width, height and depth\n",
        "    volume = resize_volume(volume)\n",
        "    return volume\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "oG6hE2yKLttO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's read the paths of the CT scans from the class directories.\n",
        "\n",
        "クラスのディレクトリからCTスキャンのパスを読み取ってみましょう。"
      ],
      "metadata": {
        "id": "zFKQuqRILttP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n",
        "# no CT-signs of viral pneumonia.\n",
        "normal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-0\")\n",
        "]\n",
        "# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n",
        "# involvement of lung parenchyma.\n",
        "abnormal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-23\")\n",
        "]\n",
        "\n",
        "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
        "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "UXo8E_7rLttP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build train and validation datasets\n",
        "Read the scans from the class directories and assign labels. Downsample the scans to have shape of 128x128x64. Rescale the raw HU values to the range 0 to 1.  \n",
        "Lastly, split the dataset into train and validation subsets.\n",
        "\n",
        "クラスのディレクトリからスキャン画像を読み込んで、ラベルを割り当てる。スキャンを128x128x64の形状にダウンサンプルする。生のHU値を0から1の範囲にリスケールする。  \n",
        "最後に、データセットを訓練用と検証用のサブセットに分割する。"
      ],
      "metadata": {
        "id": "wbZsyQWJLttP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Read and process the scans.\n",
        "# Each scan is resized across height, width, and depth and rescaled.\n",
        "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
        "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
        "\n",
        "# For the CT scans having presence of viral pneumonia\n",
        "# assign 1, for the normal ones assign 0.\n",
        "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
        "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
        "\n",
        "# Split data in the ratio 70-30 for training and validation.\n",
        "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
        "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
        "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
        "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
        "print(\n",
        "    \"Number of samples in train and validation are %d and %d.\"\n",
        "    % (x_train.shape[0], x_val.shape[0])\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "_H2zz76uLttP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation\n",
        "\n",
        "The CT scans also augmented by rotating at random angles during training.  \n",
        "Since the data is stored in rank-3 tensors of shape `(samples, height, width, depth)`, we add a dimension of size 1 at axis 4 to be able to perform 3D convolutions on the data.  \n",
        "The new shape is thus `(samples, height, width, depth, 1)`.  \n",
        "There are different kinds of preprocessing and augmentation techniques out there, this example shows a few simple ones to get started.\n",
        "\n",
        "CTスキャンもトレーニング中にランダムな角度で回転させて増強しています。  \n",
        "データはランク3のテンソルで，形状は`(samples, height, width, depth)`であるため，データに3次元の畳み込みを行えるように，軸4にサイズ1の次元を追加する。  \n",
        "新しい形状は，「(samples, height, width, depth, 1)」となります。  \n",
        "前処理や拡張技術には様々なものがありますが、この例では簡単なものをいくつか紹介します。"
      ],
      "metadata": {
        "id": "lTfqd7FELttQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import random\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def rotate(volume):\n",
        "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
        "\n",
        "    def scipy_rotate(volume):\n",
        "        # define some rotation angles\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\n",
        "        # pick angles at random\n",
        "        angle = random.choice(angles)\n",
        "        # rotate volume\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
        "        volume[volume < 0] = 0\n",
        "        volume[volume > 1] = 1\n",
        "        return volume\n",
        "\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
        "    return augmented_volume\n",
        "\n",
        "\n",
        "def train_preprocessing(volume, label):\n",
        "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
        "    # Rotate volume\n",
        "    volume = rotate(volume)\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label\n",
        "\n",
        "\n",
        "def validation_preprocessing(volume, label):\n",
        "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "haBKy1_1LttQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While defining the train and validation data loader, the training data is passed through and augmentation function which randomly rotates volume at different angles.  \n",
        "Note that both training and validation data are already rescaled to have values between 0 and 1.\n",
        "\n",
        "トレーニングデータと検証データのローダを定義する際に、トレーニングデータは、ボリュームを様々な角度でランダムに回転させるオーグメンテーション関数に渡されます。  \n",
        "なお、トレーニングデータと検証データは、0から1の間の値にリスケールされています。"
      ],
      "metadata": {
        "id": "g28VfsWJLttQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define data loaders.\n",
        "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "\n",
        "batch_size = 2\n",
        "# Augment the on the fly during training.\n",
        "train_dataset = (\n",
        "    train_loader.shuffle(len(x_train))\n",
        "    .map(train_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")\n",
        "# Only rescale.\n",
        "validation_dataset = (\n",
        "    validation_loader.shuffle(len(x_val))\n",
        "    .map(validation_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "JiihYXAdLttQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize an augmented CT scan.\n",
        "\n",
        "拡張されたCTスキャンを視覚化する。"
      ],
      "metadata": {
        "id": "iRYwyitxLttQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = train_dataset.take(1)\n",
        "images, labels = list(data)[0]\n",
        "images = images.numpy()\n",
        "image = images[0]\n",
        "print(\"Dimension of the CT scan is:\", image.shape)\n",
        "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "TXODxgu4LttQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since a CT scan has many slices, let's visualize a montage of the slices.\n",
        "\n",
        "CTスキャンはたくさんのスライスがあるので、スライスのモンタージュをイメージしてみましょう。"
      ],
      "metadata": {
        "id": "4qbQa4k5LttQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "def plot_slices(num_rows, num_columns, width, height, data):\n",
        "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
        "    data = np.rot90(np.array(data))\n",
        "    data = np.transpose(data)\n",
        "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
        "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
        "    heights = [slc[0].shape[0] for slc in data]\n",
        "    widths = [slc.shape[1] for slc in data[0]]\n",
        "    fig_width = 12.0\n",
        "    fig_height = fig_width * sum(heights) / sum(widths)\n",
        "    f, axarr = plt.subplots(\n",
        "        rows_data,\n",
        "        columns_data,\n",
        "        figsize=(fig_width, fig_height),\n",
        "        gridspec_kw={\"height_ratios\": heights},\n",
        "    )\n",
        "    for i in range(rows_data):\n",
        "        for j in range(columns_data):\n",
        "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
        "            axarr[i, j].axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Visualize montage of slices.\n",
        "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
        "plot_slices(4, 10, 128, 128, image[:, :, :40])"
      ],
      "outputs": [],
      "metadata": {
        "id": "lGH7B_g7LttQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a 3D convolutional neural network\n",
        "\n",
        "To make the model easier to understand, we structure it into blocks.  \n",
        "The architecture of the 3D CNN used in this example is based on [this paper](https://arxiv.org/abs/2007.13224).\n",
        "\n",
        "モデルを理解しやすくするために、ブロックに分けて構造化する。  \n",
        "この例で使用した3D CNNのアーキテクチャは[this paper](https://arxiv.org/abs/2007.13224)を参考にしています。"
      ],
      "metadata": {
        "id": "8zI3sC2wLttR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "def get_model(width=128, height=128, depth=64):\n",
        "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "    inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling3D()(x)\n",
        "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model.\n",
        "model = get_model(width=128, height=128, depth=64)\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "tL-3Kq2VLttR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "JtsASCipLttR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Compile model.\n",
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "\n",
        "# Define callbacks.\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"3d_image_classification.h5\", save_best_only=True\n",
        ")\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch\n",
        "epochs = 100\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "1VBVLw12LttR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that the number of samples is very small (only 200) and we don't specify a random seed.  \n",
        "As such, you can expect significant variance in the results.  \n",
        "The full dataset which consists of over 1000 CT scans can be found [here](https://www.medrxiv.org/content/10.1101/2020.05.20.20100362v1).  \n",
        "Using the full dataset, an accuracy of 83% was achieved.  \n",
        "A variability of 6-7% in the classification performance is observed in both cases.\n",
        "\n",
        "ここで重要なのは、サンプル数が非常に少なく（200個しかない）、ランダムシードを指定していないことです。  \n",
        "そのため、結果には大きなばらつきがあることが予想されます。  \n",
        "1000件以上のCTスキャンからなる完全なデータセットは[こちら](https://www.medrxiv.org/content/10.1101/2020.05.20.20100362v1)にあります。  \n",
        "このデータセットを使って、83%の精度が得られました。  \n",
        "いずれの場合も、分類性能に6〜7%のばらつきが見られます。"
      ],
      "metadata": {
        "id": "lyoTjozLLttR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing model performance\n",
        "\n",
        "Here the model accuracy and loss for the training and the validation sets are plotted.  \n",
        "Since the validation set is class-balanced, accuracy provides an unbiased representation of the model's performance.\n",
        "\n",
        "ここでは，学習セットと検証セットのモデルの精度と損失がプロットされている。  \n",
        "検証セットはクラスバランスが取れているため、精度はモデルのパフォーマンスを偏りなく表しています。"
      ],
      "metadata": {
        "id": "6dopKajgLttR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
        "    ax[i].plot(model.history.history[metric])\n",
        "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
        "    ax[i].set_title(\"Model {}\".format(metric))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(metric)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "mVJQL6EHLttR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions on a single CT scan"
      ],
      "metadata": {
        "id": "agVUgw7BLttR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load best weights.\n",
        "model.load_weights(\"3d_image_classification.h5\")\n",
        "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "\n",
        "class_names = [\"normal\", \"abnormal\"]\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(\n",
        "        \"This model is %.2f percent confident that CT scan is %s\"\n",
        "        % ((100 * score), name)\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "cANOdkmuLttR"
      }
    }
  ]
}