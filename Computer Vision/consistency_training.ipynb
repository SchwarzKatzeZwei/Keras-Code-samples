{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOuWWcBAAcor"
      },
      "source": [
        "# Consistency training with supervision(監督による一貫性のあるトレーニング)\n",
        "\n",
        "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/04/13<br>\n",
        "**Last modified:** 2021/04/19<br>\n",
        "**Description:** Training with consistency regularization for robustness against data distribution shifts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1l9GhTsAcot"
      },
      "source": [
        "深層学習モデルは、データが独立・同一分布（i.i.d.）している場合に、多くの画像認識タスクで優れた性能を発揮します。\n",
        "しかし、ランダム入力データの微妙な分布の変化（ランダムなノイズ、コントラストの変化、ぼかしなど）による性能低下に悩まされます。\n",
        "そこで、当然のことながら、次のような疑問が生じます。\n",
        "なぜかなのかは[A Fourier Perspective on Model Robustness in Computer Vision](https://arxiv.org/pdf/1906.08988.pdf)で述べたとおりです。\n",
        "深層学習モデルがそのような変化に対してロバストである理由はありません。標準的なモデルの学習手順（標準的な画像分類の学習ワークフローなど）では、\n",
        "学習データとして与えられた以上のことを学習することは*できません*。\n",
        "\n",
        "この例では、次のようにして、画像分類モデルを学習します。\n",
        "次のようにして、モデルに*一貫性*を持たせます。\n",
        "\n",
        "* 標準的な画像分類モデルを学習します。\n",
        "* 同等以上のモデルを、ノイズの多いデータセット（[RandAugment](https://arxiv.org/abs/1909.13719)）を使って補強します。\n",
        "* このためには、まず、データセットのきれいな画像に対して前のモデルの予測値を得ます。\n",
        "* 次に、この予測値を用いて、予測値と一致するように2つ目のモデルを訓練します。これは、以下のワークフローと同じです。\n",
        "[*Knowledge Distillation*](https://keras.io/examples/vision/knowledge_distillation/)のワークフローと同じですが学生モデルのサイズは同等以上なので、このプロセスは***自己訓練***のようにも呼ばれます。\n",
        "\n",
        "このような全体的なトレーニングのワークフローは、以下のような作品にルーツがあります。\n",
        "[FixMatch](https://arxiv.org/abs/2001.07685)や[Unsupervised Data Augmentation for Consistency Training](https://arxiv.org/abs/1904.12848)、\n",
        "[Noisy Student Training](https://arxiv.org/abs/1911.04252)などがあります。\n",
        "この学習プロセスは、ノイズの多い画像だけでなく、きれいな画像に対しても一貫した予測を行うようにモデルを促すので\n",
        "*一貫性のある学習*、または*一貫性正則化を用いた学習*と呼ばれています。\n",
        "この例は、一般的なノイズに対するモデルのロバスト性を高めるためのものですが弱い教師付き学習を行うためのテンプレートにもなります。\n",
        "\n",
        "この例では、TensorFlow 2.4以上、およびTensorFlow HubとTensorFlow Modelsが必要です。\n",
        "これらは次のコマンドでインストールできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gv-S49CAcou"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official tensorflow-addons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY8TMAhRAcov"
      },
      "source": [
        "## インポートとセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V59N--n_Acov"
      },
      "outputs": [],
      "source": [
        "from official.vision.image_classification.augment import RandAugment\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OufS9_orAcov"
      },
      "source": [
        "## ハイパーパラメータの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpF-BOwoAcow"
      },
      "outputs": [],
      "source": [
        "AUTO = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "\n",
        "CROP_TO = 72\n",
        "RESIZE_TO = 96"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9AQxTJ-Acow"
      },
      "source": [
        "## CIFAR-10データセットの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVPl9SxrAcox"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "val_samples = 49500\n",
        "new_train_x, new_y_train = x_train[: val_samples + 1], y_train[: val_samples + 1]\n",
        "val_x, val_y = x_train[val_samples:], y_train[val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UspF_nu6Acox"
      },
      "source": [
        "## TensorFlowの`Dataset`オブジェクトの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaK3N_DPAcoy"
      },
      "outputs": [],
      "source": [
        "# RandAugmentオブジェクトを2層の拡張変換と9の強度で初期化\n",
        "augmenter = RandAugment(num_layers=2, magnitude=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beook5yZAcoy"
      },
      "source": [
        "教師モデルの学習には，2種類の幾何学的な拡張変換（ランダムな水平反転、ランダムなクロップ）のみを使用します。\n",
        "ランダムな水平反転とランダムなクロップです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6raFLxGSAcoy"
      },
      "outputs": [],
      "source": [
        "def preprocess_train(image, label, noisy=True):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    # We first resize the original image to a larger dimension\n",
        "    # and then we take random crops from it.\n",
        "    image = tf.image.resize(image, [RESIZE_TO, RESIZE_TO])\n",
        "    image = tf.image.random_crop(image, [CROP_TO, CROP_TO, 3])\n",
        "    if noisy:\n",
        "        image = augmenter.distort(image)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def preprocess_test(image, label):\n",
        "    image = tf.image.resize(image, [CROP_TO, CROP_TO])\n",
        "    return image, label\n",
        "\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((new_train_x, new_y_train))\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UspMUP-UAcoz"
      },
      "source": [
        "`train_clean_ds`と`train_noisy_ds`が同じ種を使ってシャッフルされていることを確認します。\n",
        "これは、学生モデルのトレーニングに役立ちます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK7u5fAkAcoz"
      },
      "outputs": [],
      "source": [
        "# このデータセットは、最初のモデルの学習に使用されます\n",
        "train_clean_ds = (\n",
        "    train_ds.shuffle(BATCH_SIZE * 10, seed=42)\n",
        "    .map(lambda x, y: (preprocess_train(x, y, noisy=False)), num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "# RandAugmentを使用するために、Datasetオブジェクトを準備します。\n",
        "train_noisy_ds = (\n",
        "    train_ds.shuffle(BATCH_SIZE * 10, seed=42)\n",
        "    .map(preprocess_train, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "validation_ds = (\n",
        "    validation_ds.map(preprocess_test, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    test_ds.map(preprocess_test, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "# このデータセットは、2つ目のモデルの学習に使用されます。\n",
        "consistency_training_ds = tf.data.Dataset.zip((train_clean_ds, train_noisy_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVOJXmAPAco0"
      },
      "source": [
        "## データセットの可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNs_zbNgAco0"
      },
      "outputs": [],
      "source": [
        "sample_images, sample_labels = next(iter(train_clean_ds))\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, image in enumerate(sample_images[:9]):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"int\"))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "sample_images, sample_labels = next(iter(train_noisy_ds))\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, image in enumerate(sample_images[:9]):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"int\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUmGgx_YAco0"
      },
      "source": [
        "## モデル設定の効用関数の定義\n",
        "\n",
        "ここで、我々のモデル構築ユーティリティーを定義します。我々のモデルは、[ResNet50V2 architecture](https://arxiv.org/abs/1603.05027)に基づいています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KadsFmQYAco0"
      },
      "outputs": [],
      "source": [
        "def get_training_model(num_classes=10):\n",
        "    resnet50_v2 = tf.keras.applications.ResNet50V2(\n",
        "        weights=None, include_top=False, input_shape=(CROP_TO, CROP_TO, 3),\n",
        "    )\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            layers.Input((CROP_TO, CROP_TO, 3)),\n",
        "            layers.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
        "            resnet50_v2,\n",
        "            layers.GlobalAveragePooling2D(),\n",
        "            layers.Dense(num_classes),\n",
        "        ]\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhEpEoCjAco1"
      },
      "source": [
        "教師ネットワークの再現性を高めるために，初期のランダムな重みをシリアライズします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCXp5NC9Aco1"
      },
      "outputs": [],
      "source": [
        "initial_teacher_model = get_training_model()\n",
        "initial_teacher_model.save_weights(\"initial_teacher_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_fLEwOAco1"
      },
      "source": [
        "## 教師モデルの学習\n",
        "\n",
        "Noisy Student Trainingで述べたように、教師モデルが*幾何学的アンサンブル*で学習され、生徒モデルがそれを模倣するように強制された場合、より良い結果が得られます。\n",
        "オリジナルの研究では、[Stochastic Depth](https://arxiv.org/abs/1603.09382)と[Dropout](https://jmlr.org/papers/v15/srivastava14a.html)を使ってアンサンブルの部分を取り入れています。\n",
        "この例では、[Stochastic Weight Averaging](https://arxiv.org/abs/1803.05407)(SWA)を使います。これも幾何学的アンサンブルに似ています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KymFOHQ0Aco1"
      },
      "outputs": [],
      "source": [
        "# コールバックを定義\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# tf-hubからSWAを初期化\n",
        "SWA = tfa.optimizers.SWA\n",
        "\n",
        "# 教師モデルのコンパイルとトレーニング\n",
        "teacher_model = get_training_model()\n",
        "teacher_model.load_weights(\"initial_teacher_model.h5\")\n",
        "teacher_model.compile(\n",
        "    # オプティマイザーをSWAで包んでいることに注目してください\n",
        "    optimizer=SWA(tf.keras.optimizers.Adam()),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = teacher_model.fit(\n",
        "    train_clean_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_ds,\n",
        "    callbacks=[reduce_lr, early_stopping],\n",
        ")\n",
        "\n",
        "# テストセットで教師モデルを評価\n",
        "_, acc = teacher_model.evaluate(test_ds, verbose=0)\n",
        "print(f\"Test accuracy: {acc*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfXxaJalAco1"
      },
      "source": [
        "## セルフトレーニングユーティリティーの定義\n",
        "\n",
        "この部分では、[this Keras Example](https://keras.io/examples/vision/knowledge_distillation/)から`Distiller`クラスを借ります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBKPaYu3Aco1"
      },
      "outputs": [],
      "source": [
        "# コードの大部分は以下から引用されています\n",
        "# https://keras.io/examples/vision/knowledge_distillation/\n",
        "class SelfTrainer(tf.keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(SelfTrainer, self).__init__()\n",
        "        self.student = student\n",
        "        self.teacher = teacher\n",
        "\n",
        "    def compile(\n",
        "        self, optimizer, metrics, student_loss_fn, distillation_loss_fn, temperature=3,\n",
        "    ):\n",
        "        super(SelfTrainer, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # 今回のデータセットは、2つの独立したデータセットをZIP形式にしたものなので、\n",
        "        # 最初に解析した後、次のように画像とラベルを分離します。\n",
        "        clean_ds, noisy_ds = data\n",
        "        clean_images, _ = clean_ds\n",
        "        noisy_images, y = noisy_ds\n",
        "\n",
        "        # 教師のフォワードパス\n",
        "        teacher_predictions = self.teacher(clean_images, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # 学生のフォワードパス\n",
        "            student_predictions = self.student(noisy_images, training=True)\n",
        "\n",
        "            # 損失の計算\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            total_loss = (student_loss + distillation_loss) / 2\n",
        "\n",
        "        # グラデーションの計算\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(total_loss, trainable_vars)\n",
        "\n",
        "        # ウェイトの更新\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # compile()で設定したメトリクスの更新\n",
        "        self.compiled_metrics.update_state(\n",
        "            y, tf.nn.softmax(student_predictions, axis=1)\n",
        "        )\n",
        "\n",
        "        # パフォーマンスのディクショナリーを返す\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"total_loss\": total_loss})\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # 推論の際には、画像とラベルからなるデータセットを渡すだけです。\n",
        "        x, y = data\n",
        "\n",
        "        # 予測値の算出\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # メトリクスの更新\n",
        "        self.compiled_metrics.update_state(y, tf.nn.softmax(y_prediction, axis=1))\n",
        "\n",
        "        # パフォーマンスのディクショナリーを返す\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJo9DdPtAco1"
      },
      "source": [
        "The only difference in this implementation is the way loss is being calculated. **Instead\n",
        "of weighted the distillation loss and student loss differently we are taking their\n",
        "average following Noisy Student Training**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE-rSCxOAco2"
      },
      "source": [
        "## Train the student model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72BFyN_rAco2"
      },
      "outputs": [],
      "source": [
        "# コールバックを定義します。\n",
        "# トレーニングを安定させるために、より大きな減衰係数を使用しています。\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    patience=3, factor=0.5, monitor=\"val_accuracy\"\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10, restore_best_weights=True, monitor=\"val_accuracy\"\n",
        ")\n",
        "\n",
        "# 学生モデルのコンパイルとトレーニング\n",
        "self_trainer = SelfTrainer(student=get_training_model(), teacher=teacher_model)\n",
        "self_trainer.compile(\n",
        "    # ここではSWAを使用していないことに注意してください。\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"],\n",
        "    student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
        "    temperature=10,\n",
        ")\n",
        "history = self_trainer.fit(\n",
        "    consistency_training_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_ds,\n",
        "    callbacks=[reduce_lr, early_stopping],\n",
        ")\n",
        "\n",
        "# 学生モデルを評価する。\n",
        "acc = self_trainer.evaluate(test_ds, verbose=0)\n",
        "print(f\"Test accuracy from student model: {acc * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfn4RUNsAco2"
      },
      "source": [
        "## モデルのロバスト性の評価\n",
        "\n",
        "ビジョンモデルのロバスト性を評価する標準的なベンチマークは、ImageNet-CやCIFAR-10-Cのような破損したデータセットでのパフォーマンスを記録することです。\n",
        "[Benchmarking Neural Network Robustness to Common Corruptions and Perturbations](https://arxiv.org/abs/1903.12261)で提案されたものです。\n",
        "この例では、以下のデータセットを使用します。\n",
        "CIFAR-10-Cデータセットを使用します。CIFAR-10-Cデータセットには、5つの異なる深刻度レベルで19種類の破損があります。\n",
        "ここではこのデータセットに対するモデルのロバスト性を評価するために、以下のようにします。\n",
        "\n",
        "* 事前学習したモデルを最高レベルの深刻度で実行し、トップ1の精度を得る。\n",
        "* 平均トップ1精度を算出する。\n",
        "\n",
        "この例では、これらのステップを踏むことはありません。\n",
        "これが、今回5回のエポックのみでモデルをトレーニングした理由です。\n",
        "これは、[このリポジトリ](https://github.com/sayakpaul/Consistency-Training-with-Supervision)では\n",
        "本格的な学習実験と、前述の評価を示しています。\n",
        "下図は、その評価の概要を示しています。\n",
        "\n",
        "![](https://i.ibb.co/HBJkM9R/image.png)\n",
        "\n",
        "**平均Top-1**の結果はCIFAR-10-Cデータセット、**テストTop-1**の結果はCIFAR-10テストセットの結果です。\n",
        "一貫性のある学習は、モデルのロバスト性を向上させるだけでなく、\n",
        "標準的なテストのパフォーマンスを向上させるためにも一貫性学習が有利であることは明らかです。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "consistency_training",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
